{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "febb6c0f-306f-4241-92dc-5d579caa655f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1761250076.623819   22388 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1761250076.625139   22870 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.2.8-1ubuntu1~24.04.1), renderer: Mesa Intel(R) UHD Graphics (CML GT2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] landmarks.csv bulunamadı. Görüntüler işleniyor ve landmark'lar çıkarılıyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1761250076.645693   22857 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1761250076.676386   22866 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1761250076.691363   22867 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n",
      "Processing F: 100%|█████████████████████████| 3000/3000 [00:45<00:00, 65.82it/s]\n",
      "Processing B: 100%|█████████████████████████| 3000/3000 [00:47<00:00, 63.50it/s]\n",
      "Processing space: 100%|█████████████████████| 3000/3000 [00:57<00:00, 51.82it/s]\n",
      "Processing S: 100%|█████████████████████████| 3000/3000 [00:59<00:00, 50.44it/s]\n",
      "Processing W: 100%|█████████████████████████| 3000/3000 [01:01<00:00, 49.02it/s]\n",
      "Processing K: 100%|█████████████████████████| 3000/3000 [00:48<00:00, 61.39it/s]\n",
      "Processing Q: 100%|█████████████████████████| 3000/3000 [00:53<00:00, 56.37it/s]\n",
      "Processing Y: 100%|█████████████████████████| 3000/3000 [00:56<00:00, 52.66it/s]\n",
      "Processing T: 100%|█████████████████████████| 3000/3000 [00:49<00:00, 61.19it/s]\n",
      "Processing L: 100%|█████████████████████████| 3000/3000 [00:42<00:00, 70.98it/s]\n",
      "Processing Z: 100%|█████████████████████████| 3000/3000 [00:46<00:00, 64.35it/s]\n",
      "Processing G: 100%|█████████████████████████| 3000/3000 [00:51<00:00, 58.04it/s]\n",
      "Processing del: 100%|███████████████████████| 3000/3000 [00:53<00:00, 56.47it/s]\n",
      "Processing R: 100%|█████████████████████████| 3000/3000 [00:47<00:00, 63.49it/s]\n",
      "Processing X: 100%|█████████████████████████| 3000/3000 [00:45<00:00, 65.45it/s]\n",
      "Processing H: 100%|█████████████████████████| 3000/3000 [00:42<00:00, 70.30it/s]\n",
      "Processing I: 100%|█████████████████████████| 3000/3000 [00:43<00:00, 69.21it/s]\n",
      "Processing N: 100%|█████████████████████████| 3000/3000 [00:46<00:00, 64.92it/s]\n",
      "Processing A: 100%|█████████████████████████| 3000/3000 [00:45<00:00, 65.86it/s]\n",
      "Processing P: 100%|█████████████████████████| 3000/3000 [00:45<00:00, 66.49it/s]\n",
      "Processing U: 100%|█████████████████████████| 3000/3000 [00:47<00:00, 63.29it/s]\n",
      "Processing C: 100%|█████████████████████████| 3000/3000 [00:44<00:00, 66.98it/s]\n",
      "Processing nothing: 100%|███████████████████| 3000/3000 [00:40<00:00, 74.21it/s]\n",
      "Processing D: 100%|█████████████████████████| 3000/3000 [00:40<00:00, 74.30it/s]\n",
      "Processing E: 100%|█████████████████████████| 3000/3000 [00:43<00:00, 68.72it/s]\n",
      "Processing J: 100%|█████████████████████████| 3000/3000 [00:51<00:00, 58.39it/s]\n",
      "Processing O: 100%|█████████████████████████| 3000/3000 [00:55<00:00, 53.76it/s]\n",
      "Processing V: 100%|█████████████████████████| 3000/3000 [00:52<00:00, 57.13it/s]\n",
      "Processing M: 100%|█████████████████████████| 3000/3000 [00:57<00:00, 52.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Toplam 51382 örnek işlendi.\n",
      "[INFO] Görüntü İşleme Süresi: 1422.70 saniye\n",
      "[INFO] Landmark'lar başarıyla landmarks.csv dosyasına kaydedildi.\n",
      "\n",
      "[VERİ] Toplam Örnek: 51382, Özellik Sayısı: 63, Sınıf Sayısı: 28\n",
      "\n",
      "--- A) RANDOM FOREST EĞİTİMİ ---\n",
      "Accuracy (RF): 0.9345\n",
      "Eğitim Süresi: 5.53 saniye\n",
      "\n",
      "--- B) SVM EĞİTİMİ (Kernel=rbf) ---\n",
      "Accuracy (SVM): 0.9259\n",
      "Eğitim Süresi: 17.62 saniye\n",
      "\n",
      "--- C) TENSORFLOW ANN EĞİTİMİ ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/osman/Masaüstü/environments/sign_language_env/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "I0000 00:00:1761251544.934133   22388 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4518 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1761251546.429712   25212 service.cc:148] XLA service 0x7800a400a2a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1761251546.429841   25212 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 2060, Compute Capability 7.5\n",
      "I0000 00:00:1761251546.556936   25212 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1761251547.646645   25212 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (TF ANN): 0.9389\n",
      "Eğitim Süresi: 87.77 saniye\n",
      "\n",
      "\n",
      "--- MODEL BAŞARI VE SÜRE KARŞILAŞTIRMASI ---\n",
      "Model: RandomForest    | Doğruluk: 0.9345 | Süre: 5.53s\n",
      "Model: SVM             | Doğruluk: 0.9259 | Süre: 17.62s\n",
      "Model: TensorFlow_ANN  | Doğruluk: 0.9389 | Süre: 87.77s\n",
      "\n",
      "[SONUÇ] En iyi model: TensorFlow_ANN (Doğruluk: 0.9389)\n",
      "[KAYIT] TensorFlow modeli başarıyla best_sign_language_model.h5 olarak kaydedildi.\n",
      "[KAYIT] Label Encoder başarıyla label_encoder.joblib olarak kaydedildi.\n",
      "\n",
      "--- TensorFlow_ANN Modeli Sınıflandırma Raporu ---\n",
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step   \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.91      0.94      0.93       355\n",
      "           B       0.91      0.99      0.95       386\n",
      "           C       0.97      0.99      0.98       345\n",
      "           D       0.99      0.91      0.95       473\n",
      "           E       0.93      0.95      0.94       404\n",
      "           F       0.97      0.96      0.97       481\n",
      "           G       0.98      0.98      0.98       367\n",
      "           H       0.99      0.97      0.98       439\n",
      "           I       0.93      0.93      0.93       419\n",
      "           J       0.97      0.97      0.97       415\n",
      "           K       0.99      0.92      0.95       440\n",
      "           L       0.99      0.96      0.98       493\n",
      "           M       0.73      0.84      0.78       194\n",
      "           N       0.87      0.81      0.84       177\n",
      "           O       0.89      0.96      0.92       361\n",
      "           P       0.97      0.96      0.97       355\n",
      "           Q       0.94      0.97      0.95       311\n",
      "           R       0.94      0.83      0.88       404\n",
      "           S       0.85      0.94      0.89       361\n",
      "           T       0.95      0.90      0.92       402\n",
      "           U       0.82      0.92      0.87       352\n",
      "           V       0.90      0.93      0.91       380\n",
      "           W       0.97      0.93      0.95       373\n",
      "           X       0.92      0.88      0.90       354\n",
      "           Y       0.98      0.91      0.94       368\n",
      "           Z       0.96      0.98      0.97       429\n",
      "         del       0.96      0.98      0.97       219\n",
      "       space       0.97      0.99      0.98       220\n",
      "\n",
      "    accuracy                           0.94     10277\n",
      "   macro avg       0.93      0.94      0.93     10277\n",
      "weighted avg       0.94      0.94      0.94     10277\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Suppresses TensorFlow INFO, WARNING, ERROR\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "\n",
    "# Görüntü İşleme\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# Makine Öğrenimi (Scikit-learn)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Makine Öğrenimi (TensorFlow)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# --- SABİTLER VE KONFİGÜRASYON ---\n",
    "DATA_DIR = \"/media/osman/Yedek/datasets_signl_language/asl_sign_language/asl_alphabet_train\"\n",
    "LANDMARKS_FILE = \"landmarks.csv\"\n",
    "MODEL_FILENAME = \"best_sign_language_model.joblib\"\n",
    "LE_FILENAME = \"label_encoder.joblib\"\n",
    "\n",
    "# MediaPipe Kurulumu\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=1, min_detection_confidence=0.7)\n",
    "# static_image_mode=False olarak ayarlandı, çünkü statik olarak bir veri seti üzerinde çalışsak da \n",
    "# performans ve güvenilirlik için bazen bu daha iyidir.\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 1. LANDMARK ÇIKARMA VEYA YÜKLEME (Önbellekleme)\n",
    "# ----------------------------------------------------\n",
    "\n",
    "if os.path.exists(LANDMARKS_FILE):\n",
    "    print(f\"[INFO] {LANDMARKS_FILE} bulundu. Görüntü işleme adımı atlanıyor.\")\n",
    "    df = pd.read_csv(LANDMARKS_FILE)\n",
    "    \n",
    "    # Koordinat sütunlarını al\n",
    "    feature_cols = [col for col in df.columns if col not in ['label']]\n",
    "    X = df[feature_cols].values\n",
    "    y = df['label'].values\n",
    "else:\n",
    "    print(f\"[INFO] {LANDMARKS_FILE} bulunamadı. Görüntüler işleniyor ve landmark'lar çıkarılıyor...\")\n",
    "    \n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for label in os.listdir(DATA_DIR):\n",
    "        folder_path = os.path.join(DATA_DIR, label)\n",
    "        if not os.path.isdir(folder_path):\n",
    "            continue\n",
    "            \n",
    "        for img_file in tqdm(os.listdir(folder_path), desc=f\"Processing {label}\"):\n",
    "            img_path = os.path.join(folder_path, img_file)\n",
    "            image = cv2.imread(img_path)\n",
    "            if image is None:\n",
    "                continue\n",
    "                \n",
    "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            results = hands.process(image_rgb)\n",
    "\n",
    "            if results.multi_hand_landmarks:\n",
    "                landmark_list = []\n",
    "                # Sadece ilk algılanan eli kullan (max_num_hands=1)\n",
    "                for lm in results.multi_hand_landmarks[0].landmark:\n",
    "                    # x, y, z koordinatlarını ekle (toplam 21 * 3 = 63 özellik)\n",
    "                    landmark_list.extend([lm.x, lm.y, lm.z])\n",
    "                data.append(landmark_list)\n",
    "                labels.append(label)\n",
    "\n",
    "    print(f\"\\n[INFO] Toplam {len(data)} örnek işlendi.\")\n",
    "    print(f\"[INFO] Görüntü İşleme Süresi: {time.time() - start_time:.2f} saniye\")\n",
    "    \n",
    "    # DataFrame oluştur ve kaydet\n",
    "    num_features = 63 # 21 landmark * 3 (x, y, z)\n",
    "    column_names = [f'lm_{i}_{coord}' for i in range(21) for coord in ['x', 'y', 'z']]\n",
    "    df = pd.DataFrame(data, columns=column_names)\n",
    "    df['label'] = labels\n",
    "    \n",
    "    df.to_csv(LANDMARKS_FILE, index=False)\n",
    "    print(f\"[INFO] Landmark'lar başarıyla {LANDMARKS_FILE} dosyasına kaydedildi.\")\n",
    "    \n",
    "    X = np.array(data)\n",
    "    y = np.array(labels)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 2. VERİ ÖN İŞLEME VE BÖLME\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# Etiket Kodlama\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "n_classes = len(np.unique(y_encoded))\n",
    "input_dim = X.shape[1]\n",
    "\n",
    "print(f\"\\n[VERİ] Toplam Örnek: {X.shape[0]}, Özellik Sayısı: {input_dim}, Sınıf Sayısı: {n_classes}\")\n",
    "\n",
    "# Veri setini ayırma\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "# TensorFlow için one-hot encoding (sadece TF modeli için kullanılacak)\n",
    "y_train_tf = to_categorical(y_train, num_classes=n_classes)\n",
    "y_test_tf = to_categorical(y_test, num_classes=n_classes)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 3. MODELLERİ EĞİTME VE KARŞILAŞTIRMA\n",
    "# ----------------------------------------------------\n",
    "results = {}\n",
    "\n",
    "# --- A) Random Forest Classifier (Rastgele Orman) ---\n",
    "print(\"\\n--- A) RANDOM FOREST EĞİTİMİ ---\")\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "start_time = time.time()\n",
    "rf_model.fit(X_train, y_train)\n",
    "train_time = time.time() - start_time\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "results['RandomForest'] = {'Accuracy': accuracy_rf, 'Time': train_time, 'Model': rf_model}\n",
    "\n",
    "print(f\"Accuracy (RF): {accuracy_rf:.4f}\")\n",
    "print(f\"Eğitim Süresi: {train_time:.2f} saniye\")\n",
    "\n",
    "\n",
    "# --- B) Support Vector Machine (Destek Vektör Makineleri) ---\n",
    "# Kernel olarak 'rbf' (Radial Basis Function) yaygın kullanılır.\n",
    "print(\"\\n--- B) SVM EĞİTİMİ (Kernel=rbf) ---\")\n",
    "# C ve gamma gibi hiperparametreler denenebilir.\n",
    "svm_model = SVC(kernel='rbf', C=10, gamma='auto', random_state=42)\n",
    "start_time = time.time()\n",
    "svm_model.fit(X_train, y_train)\n",
    "train_time = time.time() - start_time\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "results['SVM'] = {'Accuracy': accuracy_svm, 'Time': train_time, 'Model': svm_model}\n",
    "\n",
    "print(f\"Accuracy (SVM): {accuracy_svm:.4f}\")\n",
    "print(f\"Eğitim Süresi: {train_time:.2f} saniye\")\n",
    "\n",
    "\n",
    "# --- C) TensorFlow (Derin Yapay Sinir Ağı - ANN) ---\n",
    "print(\"\\n--- C) TENSORFLOW ANN EĞİTİMİ ---\")\n",
    "\n",
    "tf_model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(input_dim,)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(n_classes, activation='softmax') # Çıkış katmanı, sınıf sayısı kadar nöron ve softmax\n",
    "])\n",
    "\n",
    "tf_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "history = tf_model.fit(\n",
    "    X_train, y_train_tf,\n",
    "    epochs=50, # Yüksek doğruluk için daha fazla epoch denenebilir\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test_tf),\n",
    "    verbose=0 # Çıktıyı engelle\n",
    ")\n",
    "train_time = time.time() - start_time\n",
    "\n",
    "loss, accuracy_tf = tf_model.evaluate(X_test, y_test_tf, verbose=0)\n",
    "results['TensorFlow_ANN'] = {'Accuracy': accuracy_tf, 'Time': train_time, 'Model': tf_model}\n",
    "\n",
    "print(f\"Accuracy (TF ANN): {accuracy_tf:.4f}\")\n",
    "print(f\"Eğitim Süresi: {train_time:.2f} saniye\")\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 4. BAŞARI KARŞILAŞTIRMASI VE EN İYİ MODELİN SEÇİMİ\n",
    "# ----------------------------------------------------\n",
    "\n",
    "print(\"\\n\\n--- MODEL BAŞARI VE SÜRE KARŞILAŞTIRMASI ---\")\n",
    "best_model_name = \"\"\n",
    "max_accuracy = -1\n",
    "\n",
    "for name, res in results.items():\n",
    "    print(f\"Model: {name:<15} | Doğruluk: {res['Accuracy']:.4f} | Süre: {res['Time']:.2f}s\")\n",
    "    if res['Accuracy'] > max_accuracy:\n",
    "        max_accuracy = res['Accuracy']\n",
    "        best_model_name = name\n",
    "\n",
    "print(f\"\\n[SONUÇ] En iyi model: {best_model_name} (Doğruluk: {max_accuracy:.4f})\")\n",
    "\n",
    "# En iyi modeli al\n",
    "best_model = results[best_model_name]['Model']\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 5. MODELİ VE KODLAYICIYI KAYDETME (Canlı Çalışma İçin)\n",
    "# ----------------------------------------------------\n",
    "\n",
    "if best_model_name == 'TensorFlow_ANN':\n",
    "    # TensorFlow modelini farklı kaydetme mekanizması\n",
    "    tf_model.save(MODEL_FILENAME.replace(\".joblib\", \".h5\"))\n",
    "    print(f\"[KAYIT] TensorFlow modeli başarıyla {MODEL_FILENAME.replace('.joblib', '.h5')} olarak kaydedildi.\")\n",
    "else:\n",
    "    # Scikit-learn modellerini kaydetme (Joblib)\n",
    "    joblib.dump(best_model, MODEL_FILENAME)\n",
    "    print(f\"[KAYIT] {best_model_name} modeli başarıyla {MODEL_FILENAME} olarak kaydedildi.\")\n",
    "\n",
    "# Label Encoder'ı kaydet\n",
    "joblib.dump(le, LE_FILENAME)\n",
    "print(f\"[KAYIT] Label Encoder başarıyla {LE_FILENAME} olarak kaydedildi.\")\n",
    "\n",
    "# Örnek Sınıflandırma Raporu (En iyi model için)\n",
    "print(f\"\\n--- {best_model_name} Modeli Sınıflandırma Raporu ---\")\n",
    "if best_model_name != 'TensorFlow_ANN':\n",
    "    final_y_pred = best_model.predict(X_test)\n",
    "    print(classification_report(y_test, final_y_pred, target_names=le.classes_))\n",
    "else:\n",
    "    # TF model çıktısını decode et\n",
    "    final_y_pred_tf = tf_model.predict(X_test)\n",
    "    final_y_pred = np.argmax(final_y_pred_tf, axis=1)\n",
    "    print(classification_report(y_test, final_y_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ea3eca-015a-4dbd-b49e-8af4ce9c9ba5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36417c37-9b56-4c6f-b646-dc1d747227e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
