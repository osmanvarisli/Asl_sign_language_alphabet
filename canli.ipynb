{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bb33a4c-61a4-4ccf-b4d1-95d7dfc70a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-28 21:24:52.200288: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1761675892.245744   39747 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1761675892.259318   39747 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-10-28 21:24:52.381755: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Label Encoder yüklendi. Sınıflar: ['A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J' 'K' 'L' 'M' 'N' 'O' 'P' 'Q' 'R'\n",
      " 'S' 'T' 'U' 'V' 'W' 'X' 'Y' 'Z' 'del' 'space']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1761675895.941625   39747 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4497 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1761675896.911984   39747 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1761675896.916034   39944 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.2.8-1ubuntu1~24.04.1), renderer: Mesa Intel(R) UHD Graphics (CML GT2)\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1761675896.952509   39933 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1761675896.974848   39936 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] TensorFlow modeli (best_sign_language_model.h5) yüklendi.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1761675899.253155   39932 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1761675899.339657   39862 service.cc:148] XLA service 0x7842180055d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1761675899.339799   39862 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 2060, Compute Capability 7.5\n",
      "2025-10-28 21:24:59.348445: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1761675899.377381   39862 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1761675899.543636   39862 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Canlı algılama sonlandırıldı.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import joblib\n",
    "import mediapipe as mp\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Sabitler\n",
    "MODEL_FILENAME = \"best_sign_language_model.joblib\"\n",
    "LE_FILENAME = \"label_encoder.joblib\"\n",
    "TF_MODEL_FILENAME = \"best_sign_language_model.h5\"\n",
    "\n",
    "# --- 1. MODELİ VE KODLAYICIYI YÜKLEME ---\n",
    "\n",
    "# Label Encoder'ı yükle\n",
    "try:\n",
    "    le = joblib.load(LE_FILENAME)\n",
    "    class_names = le.classes_\n",
    "    print(f\"[INFO] Label Encoder yüklendi. Sınıflar: {class_names}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"[HATA] {LE_FILENAME} bulunamadı. Lütfen eğitim kodunu çalıştırın.\")\n",
    "    exit()\n",
    "\n",
    "# Eğitilmiş modeli yükle (TF veya Scikit-learn)\n",
    "if os.path.exists(TF_MODEL_FILENAME):\n",
    "    try:\n",
    "        model = load_model(TF_MODEL_FILENAME)\n",
    "        model_type = \"TensorFlow ANN\"\n",
    "        print(f\"[INFO] TensorFlow modeli ({TF_MODEL_FILENAME}) yüklendi.\")\n",
    "    except Exception as e:\n",
    "        print(f\"[HATA] TensorFlow modeli yüklenirken bir hata oluştu: {e}\")\n",
    "        exit()\n",
    "elif os.path.exists(MODEL_FILENAME):\n",
    "    try:\n",
    "        model = joblib.load(MODEL_FILENAME)\n",
    "        model_type = \"Scikit-learn\"\n",
    "        print(f\"[INFO] Scikit-learn modeli ({MODEL_FILENAME}) yüklendi.\")\n",
    "    except Exception as e:\n",
    "        print(f\"[HATA] Scikit-learn modeli yüklenirken bir hata oluştu: {e}\")\n",
    "        exit()\n",
    "else:\n",
    "    print(f\"[HATA] Kaydedilmiş model ({MODEL_FILENAME} veya {TF_MODEL_FILENAME}) bulunamadı.\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# --- 2. MEDIAPIPE VE KAMERA KURULUMU ---\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# MediaPipe Hands modelini başlat\n",
    "# Canlı akış olduğu için static_image_mode=False\n",
    "hands = mp_hands.Hands(\n",
    "    static_image_mode=False,\n",
    "    max_num_hands=1,\n",
    "    min_detection_confidence=0.7,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "# Kamera başlatma\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"[HATA] Kamera açılamadı.\")\n",
    "    exit()\n",
    "\n",
    "# Tahmin sonuçları\n",
    "predicted_label = \"Bekleniyor...\"\n",
    "\n",
    "# --- 3. CANLI YAKALAMA DÖNGÜSÜ ---\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "        print(\"[HATA] Görüntü alınamıyor.\")\n",
    "        continue\n",
    "\n",
    "    # Performans için görüntüyü yatay çevir (selfie modu)\n",
    "    image = cv2.flip(image, 1)\n",
    "\n",
    "    # BGR'dan RGB'ye dönüştür ve sadece okunur yap\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image_rgb.flags.writeable = False\n",
    "\n",
    "    # MediaPipe ile işleme\n",
    "    results = hands.process(image_rgb)\n",
    "\n",
    "    # Çizim için tekrar yazılabilir yap\n",
    "    image_rgb.flags.writeable = True\n",
    "    image = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    # Landmark'ları topla\n",
    "    landmark_list = []\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        # Algılanan her el için (Bizim modelimiz tek el için)\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            \n",
    "            # Landmark'ları çiz\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image, \n",
    "                hand_landmarks, \n",
    "                mp_hands.HAND_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(121, 22, 76), thickness=2, circle_radius=4), # Nokta rengi\n",
    "                mp_drawing.DrawingSpec(color=(250, 44, 250), thickness=2, circle_radius=2)  # Çizgi rengi\n",
    "            )\n",
    "\n",
    "            # Landmark verilerini model için hazırla\n",
    "            for lm in hand_landmarks.landmark:\n",
    "                # x, y, z koordinatlarını ekle\n",
    "                landmark_list.extend([lm.x, lm.y, lm.z])\n",
    "\n",
    "            # Modelin tahminini yap\n",
    "            if len(landmark_list) == 63: # 21 landmark * 3 koordinat\n",
    "                X_pred = np.array([landmark_list])\n",
    "\n",
    "                # Tahmini al\n",
    "                if model_type == \"TensorFlow ANN\":\n",
    "                    # TF modeli için tahmin ve argmax (en yüksek olasılıklı sınıf)\n",
    "                    prediction = model.predict(X_pred, verbose=0)\n",
    "                    predicted_class_index = np.argmax(prediction[0])\n",
    "                else:\n",
    "                    # Scikit-learn modeli için tahmin\n",
    "                    predicted_class_index = model.predict(X_pred)[0]\n",
    "                \n",
    "                # Sayısal indeksi harf etiketine dönüştür\n",
    "                predicted_label = class_names[predicted_class_index]\n",
    "            else:\n",
    "                predicted_label = \"Veri Hatası\"\n",
    "\n",
    "    # Tahmin sonucunu ekranda göster\n",
    "    cv2.putText(\n",
    "        image, \n",
    "        f\"Tahmin: {predicted_label}\", \n",
    "        (10, 30), \n",
    "        cv2.FONT_HERSHEY_SIMPLEX, \n",
    "        1, # font scale\n",
    "        (0, 255, 0), # yeşil renk\n",
    "        2, # kalınlık\n",
    "        cv2.LINE_AA\n",
    "    )\n",
    "    \n",
    "    cv2.putText(\n",
    "        image, \n",
    "        f\"Model: {model_type}\", \n",
    "        (10, image.shape[0] - 10), \n",
    "        cv2.FONT_HERSHEY_SIMPLEX, \n",
    "        0.5, # font scale\n",
    "        (255, 255, 255), # beyaz renk\n",
    "        1, # kalınlık\n",
    "        cv2.LINE_AA\n",
    "    )\n",
    "\n",
    "    # Görüntüyü göster\n",
    "    cv2.imshow('ASL Isaret Dili Tanima', image)\n",
    "\n",
    "    # 'q' tuşuna basılırsa döngüden çık\n",
    "    if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# --- 4. TEMİZLEME ---\n",
    "hands.close()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"[INFO] Canlı algılama sonlandırıldı.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ef6edd-e18e-4cd0-860f-ccd5907c59e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
